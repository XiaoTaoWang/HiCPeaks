#!/usr/bin/env python

# Created on Thu Apr 30 15:15:30 2015

# Author: XiaoTao Wang

from __future__ import division
import argparse, sys, logging, logging.handlers, hicpeaks

import numpy as np
from scipy import sparse

currentVersion = hicpeaks.__version__

def getargs():
    ## Construct an ArgumentParser object for command-line arguments
    parser = argparse.ArgumentParser(usage = '%(prog)s <-O output> [options]',
                                     description = 'Local Peak Calling for Hi-C Data',
                                     formatter_class = argparse.ArgumentDefaultsHelpFormatter)
    
    # Version
    parser.add_argument('-v', '--version', action='version',
                        version=' '.join(['%(prog)s',currentVersion]),
                        help='Print version number and exit.')

    # Output
    parser.add_argument('-O', '--output', help = 'Output peak file path.')
    parser.add_argument('--logFile', default = 'HICCUPS.log', help = 'Logging file name.')
    
    group_1 = parser.add_argument_group(title = 'Relate to Hi-C data:')
    group_1.add_argument('-p', '--path',
                         help = 'URI string pointing to a cooler under specific resolution.')
    group_1.add_argument('-C', '--chroms', nargs = '*', default = ['#', 'X'],
                        help = 'List of chromosome labels. Only Hi-C data within the specified '
                        'chromosomes will be included. Specially, "#" stands for chromosomes '
                        'with numerical labels. "--chroms" with zero argument will include '
                        'all chromosome data.')
    
    ## About the algorithm
    group_2 = parser.add_argument_group(title = 'Algorithm Parameters:')
    group_2.add_argument('--pw', type = int, default = 2, help = 'Width of the interaction '
                         'region surrounding the peak. According to experience, we set it'
                         ' to 1 at 20 kb, 2 at 10 kb, and 4 at 5 kb.')
    group_2.add_argument('--ww', type = int, default = 5, help = 'Width of the donut '
                         'sampled. Set it to 3 at 20 kb, 5 at 10 kb, and 7 at 5 kb.')
    group_2.add_argument('--maxww', type = int, default = 20, help = 'Maximum donut width.')
    group_2.add_argument('--siglevel', type = float, default = 0.1, help = 'Significant Level.')
    group_2.add_argument('--maxapart', type = int, default = 5000000, help = 'Maximum genomic'
                         ' distance between two involved loci.')
    group_2.add_argument('--nproc', type = int, default = 1, help = 'Number of worker processes.')
    
    ## Parse the command-line arguments
    commands = sys.argv[1:]
    if not commands:
        commands.append('-h')
    args = parser.parse_args(commands)
    
    return args, commands

def run():
     # Parse Arguments
    args, commands = getargs()
    # Improve the performance if you don't want to run it
    if commands[0] not in ['-h', '--help']:
        ## Root Logger Configuration
        logger = logging.getLogger()
        # Logger Level
        logger.setLevel(10)
        console = logging.StreamHandler()
        filehandler = logging.handlers.RotatingFileHandler(args.logFile,
                                                           maxBytes = 200000,
                                                           backupCount = 5)
        # Set level for Handlers
        console.setLevel('INFO')
        filehandler.setLevel('DEBUG')
        # Customizing Formatter
        formatter = logging.Formatter(fmt = '%(name)-14s %(levelname)-7s @ %(asctime)s: %(message)s',
                                      datefmt = '%m/%d/%y %H:%M:%S')
        
        console.setFormatter(formatter)
        filehandler.setFormatter(formatter)
        # Add Handlers
        logger.addHandler(console)
        logger.addHandler(filehandler)
        
        ## Logging for argument setting
        arglist = ['# ARGUMENT LIST:',
                   '# Output file = {}'.format(args.output),
                   '# Cooler URI = {}'.format(args.path),
                   '# Chromosomes = {}'.format(args.chroms),
                   '# Peak window width = {}'.format(args.pw),
                   '# Donut width = {}'.format(args.ww),
                   '# Maximum donut width = {}'.format(args.maxww),
                   '# Significant Level = {}'.format(args.siglevel),
                   '# Maximum Genomic distance = {}'.format(args.maxapart),
                   '# Number of Processes = {}'.format(args.nproc)
                   ]
        
        argtxt = '\n'.join(arglist)
        logger.info('\n'+argtxt)
        
        # Package Dependencies
        import cooler
        from multiprocess import Pool
        from sklearn import isotonic

        def worker(tuple_arg):
            Lib, key, pw, ww, siglevel, maxww, maxapart, resolution = tuple_arg
            logger.info('Chromosome %s ...', key)
            H = Lib.matrix(balance=False, sparse=True).fetch(key)
            # Customize Sparse RAW Matrix ...
            chromLen = H.shape[0]
            num = args.maxapart // resolution + args.maxww + 1
            Diags = [H.diagonal(i) for i in np.arange(num)]
            del H
            M = sparse.diags(Diags, np.arange(num), format='csr')

            cHeatMap = Lib.matrix(balance=True, sparse=True).fetch(key)
            # Customize Sparse ICE Matrix ...
            x = np.arange(args.ww, num)
            y = []
            cDiags = []
            for i in x:
                diag = cHeatMap.diagonal(i)
                mask = np.isnan(diag)
                notnan = diag[np.logical_not(mask)]
                y.append(notnan.mean())
                diag[mask] = 0
                cDiags.append(diag)
            del cHeatMap
            cM = sparse.diags(cDiags, x, format='csr')
            IR = isotonic.IsotonicRegression(increasing='auto')
            IR.fit(x, y)

            tmp = Lib.bins().fetch(key)['weight'].values
            mask = np.logical_not(tmp==0)
            biases = np.zeros_like(tmp)
            biases[mask] = 1/tmp[mask]

            Donuts, LL = pcaller(M, cM, biases, IR, chromLen, Diags, cDiags, num, key,
                                pw=pw, ww=ww, sig=siglevel, maxww=maxww, maxapart=maxapart,
                                res=resolution)
            
            return key, Donuts, LL
        
        logger.info('Loading Hi-C data ...')
        Lib = cooler.Cooler(args.path)
        resolution = Lib.binsize

        if args.nproc == 1:
            map_ = map
        else:
            pool = Pool(args.nproc)
            map_ = pool.map
        
        logger.info('Calling Peaks ...')
        OF = open(args.output, 'wb')
        head = '\t'.join(['chromLabel', 'loc_1', 'loc_2', 'IF', 'D-Enrichment', 'D-pvalue', 'D-qvalue',
                          'LL-Enrichment', 'LL-pvalue', 'LL-qvalue']) + '\n'
        OF.write(head)
        
        Params = []
        for key in Lib.chromnames:
            if ((not args.chroms) or (key.isdigit() and '#' in args.chroms) or (key in args.chroms)):
                Params.append((Lib, key, args.pw, args.ww, args.siglevel, args.maxww, args.maxapart, resolution))
        
        results = map_(worker, Params)

        for key, Donuts, LL in results:
            for i in Donuts:
                lineFormat = '{0}\t{1}\t{2}\t{3:.4g}\t{4:.4g}\t{5:.4g}\t{6:.4g}\t{7:.4g}\t{8:.4g}\t{9:.4g}\n'
                contents = (key,) + i + Donuts[i] + LL[i][1:]
                line = lineFormat.format(*contents)
                OF.write(line)        
                    
        OF.flush()
        OF.close()
                            
        logger.info('Done!')

def pcaller(M, cM, biases, IR, chromLen, Diags, cDiags, num, chrom, pw=2, ww=5, sig=0.05, maxww=20,
            maxapart=2000000, res=10000):
    
    # Necessary Modules
    from scipy.stats import poisson
    from statsmodels.sandbox.stats.multicomp import multipletests
    
    logger = logging.getLogger()
    
    def extDiags(w, i):
        OneDArray = M.diagonal(i)
        extODA = np.zeros(chromLen - i + w*2)
        extODA[w:-w] = OneDArray

        return extODA
    
    def extCDiags(w, i):

        OneDArray = np.zeros(chromLen - predict)
    
    x = np.arange(ww, num)
    predictE = IR.predict(x)
    predictE[predictE < 0] = 0
    predictE = dict(zip(range(x.size), zip(x, predictE)))
    EDiags = []
    for i in range(x.size):
        OneDArray = np.ones(chromLen - predictE[i][0]) * predictE[i][1]
        EDiags.append(OneDArray)
    
    EM = sparse.diags(EDiags, x, format = 'csr')

    del EDiags
    
    extCDiags = {}
    extEDiags = {}
    for w in range(ww, maxww + 1):
        tempC = []
        tempE = []
        for i in xrange(x.size):
            extODA_E = np.zeros(chromLen - x[i] + w*2)
            extODA_E[w:-w] = EDiags[i]
            tempE.append(extODA_E)
            extODA_C = np.zeros(chromLen - x[i] + w*2)
            extODA_C[w:-w] = cDiags[i]
            tempC.append(extODA_C)
        extCDiags[w] = tempC
        extEDiags[w] = tempE
    
    ps = 2 * pw + 1 # Peak Size
    
    Pool_Diags = {}
    Pool_EDiags = {}
    Pool_cDiags = {}
    Offsets_Diags = {}
    Offsets_EDiags = {}
    
    for w in range(ww, maxww + 1):
        ws = 2 * w + 1 # Window size
        ss = range(ws)
        Pool_Diags[w] = {}
        Pool_EDiags[w] = {}
        Pool_cDiags[w] = {}
        Offsets_Diags[w] = {}
        Offsets_EDiags[w] = {}
        for i in ss:
            for j in ss:
                Pool_Diags[w][(i,j)] = []
                Pool_EDiags[w][(i,j)] = []
                Pool_cDiags[w][(i,j)] = []
                Offsets_Diags[w][(i,j)] = np.arange(num) + (i - j)
                Offsets_EDiags[w][(i,j)] = x + (i - j)
                for oi in np.arange(num):
                    if Offsets_Diags[w][(i,j)][oi] >= 0:
                        starti = i
                        endi = i + chromLen - Offsets_Diags[w][(i,j)][oi]
                    else:
                        starti = i - Offsets_Diags[w][(i,j)][oi]
                        endi = starti + chromLen + Offsets_Diags[w][(i,j)][oi]
                    Pool_Diags[w][(i,j)].append(extDiags(w,oi)[starti:endi])
                for oi in xrange(x.size):
                    if Offsets_EDiags[w][(i,j)][oi] >= 0:
                        starti = i
                        endi = i + chromLen - Offsets_EDiags[w][(i,j)][oi]
                    else:
                        starti = i - Offsets_EDiags[w][(i,j)][oi]
                        endi = starti + chromLen + Offsets_EDiags[w][(i,j)][oi]
                    Pool_EDiags[w][(i,j)].append(extEDiags[w][oi][starti:endi])
                    Pool_cDiags[w][(i,j)].append(extCDiags[w][oi][starti:endi])
                
    ## Peak Calling ...    
    xi, yi = M.nonzero()
    Mask = ((yi - xi) >= ww) & ((yi - xi) <= (maxapart // res))
    xi = xi[Mask]
    yi = yi[Mask]
    flocals = ['K', 'Y']
    bSV = {}; bEV = {}
    for fl in flocals:
        bSV[fl] = np.zeros(xi.size)
        bEV[fl] = np.zeros(xi.size)
    
    logger.info('Chrom:{0}, Observed Contact Number: {1}'.format(chrom, xi.size))
    
    RefIdx = np.arange(xi.size)
    RefMask = np.ones_like(xi, dtype = bool)
    
    iniNum = xi.size
    
    logger.info('Chrom:{0}, Two local neighborhoods, two expected matrices ...'.format(chrom))
    for w in range(ww, maxww + 1):
        ws = 2 * w + 1
        bS = {}; bE = {}
        for fl in flocals:
            bS[fl] = sparse.csr_matrix((chromLen, chromLen))
            bE[fl] = sparse.csr_matrix((chromLen, chromLen))
        Reads = sparse.csr_matrix((chromLen, chromLen))
        logger.info('Chrom:{0},    Current window width: {1}'.format(chrom, w))
        P1 = set([(i,j) for i in range(w-pw, ps+w-pw) for j in range(w-pw, ps+w-pw)]) # Center Peak Region
        P_1 = set([(i,j) for i in range(w+1, ws) for j in range(w)])
        P_2 = set([(i,j) for i in range(w+1, ps+w-pw) for j in range(w-pw, w)])
        P2 = P_1 - P_2 # Lower-left Region
        
        for key in Pool_Diags[w]:
            if (key[0] != w) and (key[1] != w) and (key not in P1) and (key not in P2):
                bS['K'] = bS['K'] + sparse.diags(Pool_cDiags[w][key], Offsets_EDiags[w][key], format = 'csr')
                bE['K'] = bE['K'] + sparse.diags(Pool_EDiags[w][key], Offsets_EDiags[w][key], format = 'csr')
            if key in P2:
                bS['K'] = bS['K'] + sparse.diags(Pool_cDiags[w][key], Offsets_EDiags[w][key], format = 'csr')
                bE['K'] = bE['K'] + sparse.diags(Pool_EDiags[w][key], Offsets_EDiags[w][key], format = 'csr')
                bS['Y'] = bS['Y'] + sparse.diags(Pool_cDiags[w][key], Offsets_EDiags[w][key], format = 'csr')
                bE['Y'] = bE['Y'] + sparse.diags(Pool_EDiags[w][key], Offsets_EDiags[w][key], format = 'csr')
                Reads = Reads + sparse.diags(Pool_Diags[w][key], Offsets_Diags[w][key], format = 'csr')
                
        Txi = xi[RefIdx]
        Tyi = yi[RefIdx]
        RNums = np.array(Reads[Txi, Tyi]).ravel()
        EIdx = RefIdx[RNums >= 16]
        logger.info('Chrom:{0},    Valid Contact Number: {1}'.format(chrom, EIdx.size))
        Valid_Ratio = EIdx.size/float(iniNum)
        logger.info('Chrom:{0},    Valid Contact Ratio: {1:.3f}'.format(chrom, Valid_Ratio))
        Exi = xi[EIdx]
        Eyi = yi[EIdx]
        for fl in flocals:
            bSV[fl][EIdx] = np.array(bS[fl][Exi, Eyi]).ravel()
            bEV[fl][EIdx] = np.array(bE[fl][Exi, Eyi]).ravel()
                
        RefIdx = RefIdx[RNums < 16]
            
        iniNum = RefIdx.size
        
        if Valid_Ratio < 0.1:
            logger.info('Chrom:{0},    Ratio of valid contact is too small, break the loop ...'.format(chrom))
            break
        
        logger.info('Chrom:{0},    Continue ...'.format(chrom))
        logger.info('Chrom:{0},    {1} Contacts will get into next loop ...'.format(chrom, RefIdx.size))
    
    RefMask[RefIdx] = False
    
    Mask = (bEV['K'] != 0) & (bEV['Y'] != 0) & RefMask
    xi = xi[Mask]
    yi = yi[Mask]
    bRV = {}
    for fl in flocals:
        bRV[fl] = bSV[fl][Mask] / bEV[fl][Mask]
    
    bR = {}
    for fl in flocals:
        bR[fl] = sparse.csr_matrix((chromLen, chromLen))
        bR[fl][xi, yi] = bRV[fl]
    
    ## Corrected Expected Matrix
    cEM = {}
    for fl in flocals:
        cEM[fl] = EM.multiply(bR[fl])
    
    logger.info('Chrom:{0}, Poisson Models and Benjamini-Hochberg Correcting for lambda chunks ...'.format(chrom))
    Description = {'K': 'Donut backgrounds', 'Y': 'Lower-left backgrounds'}
    xpos = {}; ypos = {}; Ovalues = {}; Evalues = {}
    Fold = {}; pvalues = {}; qvalues = {}
    gaps = set(np.where(np.array(M.sum(axis=1)).ravel() == 0)[0])
    for fl in flocals:
        logger.info('Chrom:{0},    {1} ...'.format(chrom, Description[fl]))
        xi, yi = cEM[fl].nonzero()
        Evalues[fl] = np.array(cEM[fl][xi, yi]).ravel() * biases[xi] * biases[yi]
        Mask = (Evalues[fl] > 0)
        Evalues[fl] = Evalues[fl][Mask]
        xi = xi[Mask]
        yi = yi[Mask]
        Ovalues[fl] = np.array(M[xi, yi]).ravel()
        Fold[fl] =  Ovalues[fl] / Evalues[fl]
        logger.info('Chrom:{0},    Valid contact number: {1}'.format(chrom, xi.size))
        
        pvalue = np.ones(xi.size)
        qvalue = np.ones(xi.size)
        
        logger.info('Chrom:{0},    Lambda chunking ...'.format(chrom))
        chunks = lambdachunk(Evalues[fl])
        logger.info('Chrom:{0},    Number of chunks: {1}'.format(chrom, len(chunks)))
        for chunk in chunks:
            logger.debug('Chrom:{0},        lv: {1:.4g}, rv: {2:.4g}, Num: {3}'.format(chrom, chunk[0], chunk[1], chunk[2].size))
            if chunk[2].size > 0:
                Poiss = poisson(chunk[1])
                logger.debug('Chrom:{0},        Assign P values ...'.format(chrom))
                chunkP = 1 - Poiss.cdf(Ovalues[fl][chunk[2]])
                pvalue[chunk[2]] = chunkP
                logger.debug('Chrom:{0},        Multiple testing ...'.format(chrom))
                cResults = multipletests(chunkP, alpha = sig, method = 'fdr_bh')
                cP = cResults[1] # Corrected Pvalue
                qvalue[chunk[2]] = cP
            else:
                logger.debug('Chrom:{0},        Skipping ...'.format(chrom))
        
        reject = qvalue <= sig
        qvalue = qvalue[reject]
        pvalue = pvalue[reject]
        Ovalues[fl] = Ovalues[fl][reject]
        Evalues[fl] = Evalues[fl][reject]
        Fold[fl] = Fold[fl][reject]
        xi = xi[reject]
        yi = yi[reject]
        
        logger.info('Chrom:{0},    Remove Gap Effects ...'.format(chrom))
        
        if len(gaps) > 0:
            fIdx = []
            for i in xrange(xi.size):
                lower = (xi[i] - 5) if (xi[i] > 5) else 0
                upper = (xi[i] + 5) if ((xi[i] + 5) < chromLen) else (chromLen - 1)
                cregion_1 = range(lower, upper)
                lower = (yi[i] - 5) if (yi[i] > 5) else 0
                upper = (yi[i] + 5) if ((yi[i] + 5) < chromLen) else (chromLen - 1)
                cregion_2 = range(lower, upper)
                cregion = set(cregion_1) | set(cregion_2)
                intersect = cregion & gaps
                if len(intersect) == 0:
                    fIdx.append(i)
        
            xi = xi[fIdx]
            yi = yi[fIdx]
            Ovalues[fl] = Ovalues[fl][fIdx]
            pvalue = pvalue[fIdx]
            qvalue = qvalue[fIdx]
            Fold[fl] = Fold[fl][fIdx]
            Evalues[fl] = Evalues[fl][fIdx]
        
        xpos[fl] = xi
        ypos[fl] = yi
        pvalues[fl] = pvalue
        qvalues[fl] = qvalue
    
    logger.info('Chrom:{0}, Combine two local filters ...'.format(chrom))
    
    preDonuts = dict(zip(zip(xpos['K']*res, ypos['K']*res), zip(Ovalues['K'], Fold['K'], pvalues['K'], qvalues['K'])))
    preLL = dict(zip(zip(xpos['Y']*res, ypos['Y']*res), zip(Ovalues['Y'], Fold['Y'], pvalues['Y'], qvalues['Y'])))
    
    commonPos = set(preDonuts.keys()) & set(preLL.keys())
    Donuts = {}; LL = {}
    for pos in commonPos:
        Donuts[pos] = preDonuts[pos]
        LL[pos] = preLL[pos]
    
    return Donuts, LL

def lambdachunk(E):
    
    numbin = np.int(np.ceil(np.log(E.max()) / np.log(2) * 3 + 1))
    Pool = []
    for i in xrange(1, numbin + 1):
        if i == 1:
            lv = 0; rv = 1
        else:
            lv = np.power(2, ((i - 2)/3.))
            rv = np.power(2, ((i - 1)/3.))
        idx = np.where((E > lv) & (E < rv))[0]
        Pool.append((lv, rv, idx))
    
    return Pool
    

if __name__ == '__main__':
    run()
